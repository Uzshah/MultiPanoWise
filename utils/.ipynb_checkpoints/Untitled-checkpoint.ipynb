{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f83591-69d0-496d-8c4c-c00a73ad565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d815b3-c9d2-4277-ad26-5e8c000d677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        'EfficientFormer training and evaluation script', add_help=False)\n",
    "    parser.add_argument('--batch-size', default=8, type=int)\n",
    "    parser.add_argument('--epochs', default=50, type=int)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--model', default='S_EleViTDecoder', type=str, metavar='MODEL',\n",
    "                        help='Name of model to train')\n",
    "    parser.add_argument('--input-size', default=[256, 512],\n",
    "                        type=int, help='images input size')\n",
    "\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--opt', default='AdamW', type=str, metavar='OPTIMIZER',\n",
    "                        help='Optimizer (default: \"adamw\"')\n",
    "    \n",
    "    # Learning rate schedule parameters\n",
    "    parser.add_argument('--sched', default='CosineAnnealingLR', type=str, metavar='SCHEDULER',\n",
    "                        help='LR scheduler (default: \"cosine\"')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3, metavar='LR',\n",
    "                        help='learning rate (default: 1e-3)')\n",
    "\n",
    "\n",
    "    # Loss parameters\n",
    "    parser.add_argument('--loss', default='DepthL1Loss', choices=['DepthL1Loss',  'FullLoss'],\n",
    "                        type=str, help='Image Net dataset path')\n",
    "    # semantic Loss parameters\n",
    "    parser.add_argument('--se_loss', default='CrossEntropyLoss', choices=['CrossEntropyLoss',  'FullLoss'],\n",
    "                        type=str, help='Image Net dataset path')\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--validation_split', default=0.15,\n",
    "                        type=float, help='images input size')\n",
    "    parser.add_argument('--metric_scale', default=512.0,\n",
    "                        type=float, help='images input size')\n",
    "    parser.add_argument('--dataset', default='s3d', choices=['s3d', 'ade20k'],\n",
    "                        type=str, help='Image Net dataset path')\n",
    "    parser.add_argument('--folders', default=['Data/full'], type = int, \n",
    "                        nargs=\"*\",help='Image Net dataset path')\n",
    "    \n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--output_dir', default='check_points',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--eval', default='',\n",
    "                        help='path from where to load')\n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                        help='device to use for training / testing')\n",
    "    parser.add_argument('--seed', default=2023, type=int)\n",
    "    parser.add_argument('--dist-eval', action='store_true',\n",
    "                        default=False, help='Enabling distributed evaluation')\n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    parser.add_argument('--option', default='all', type=str, choices=['all',  'semantic', 'depth', 'alb_shading'])\n",
    "    parser.add_argument('--outsize', default=1, type=int)\n",
    "    parser.add_argument('--pin-mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "    parser.add_argument('--no-pin-mem', action='store_false', dest='pin_mem',\n",
    "                        help='')\n",
    "    parser.set_defaults(pin_mem=True)\n",
    "    \n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--dist_url', default='env://',\n",
    "                        help='url used to set up distributed training')\n",
    "    \n",
    "    return parser\n",
    "parser = argparse.ArgumentParser(parents=[get_args_parser()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ae1ae0-6a3c-47c7-8ac4-54fb3648f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args_parser()\n",
    "args.input_size = [256, 512]\n",
    "args.outsize = 1\n",
    "args.dataset = 's3d'\n",
    "args.folders = [\"../Data/full\"]\n",
    "args.validation_split = 0.1\n",
    "args.option = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a43bbb6a-f5cc-4747-8894-be01a7e8b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import build_dataset\n",
    "import numpy as np\n",
    "train_dataset, test_dataset = build_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee510d5f-02f2-40e5-87f0-138bd59898f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "527ae064-3159-49b4-85c5-027bed6a271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6302cf7-21cf-4d9a-aa16-c2263dab7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import filters\n",
    "def reconstruct(d_batch):\n",
    "    \"\"\"\n",
    "    Compute equirectangular normal map from the equirectangular depth map for a batch of depth maps.\n",
    "\n",
    "    Parameters:\n",
    "    d_batch (numpy.ndarray): Batch of depth maps (equirectangular projection) in millimeters.\n",
    "                            Shape: (batch_size, height, width)\n",
    "\n",
    "    Returns:\n",
    "    n_hat_batch (numpy.ndarray): Batch of equirectangular normal maps.\n",
    "                                Shape: (batch_size, height, width, 3)\n",
    "    \"\"\"\n",
    "    batch_size, _, height, width = d_batch.shape\n",
    "\n",
    "    # Compute gradients of the depth maps using Sobel filters\n",
    "    d_theta = np.array([filters.scharr_h(d.squeeze(0).numpy()) for d in d_batch])\n",
    "    d_phi = np.array([filters.scharr_v(d.squeeze(0).numpy()) for d in d_batch])\n",
    "\n",
    "    # Constants for converting pixel indices to spherical angles\n",
    "    k_u = np.pi / height\n",
    "    k_v = 2.0 * np.pi / width\n",
    "\n",
    "    # Create meshgrids for theta and phi\n",
    "    j = np.arange(height) + 0.5\n",
    "    i = np.arange(width) + 0.5\n",
    "    theta, phi = np.meshgrid(k_u * j, k_v * i - np.pi, indexing='ij')\n",
    "\n",
    "    # Compute vectors in spherical coordinates\n",
    "    r = np.stack((np.sin(theta) * np.cos(phi),\n",
    "                  np.cos(theta),\n",
    "                  -np.sin(theta) * np.sin(phi)), axis=-1)\n",
    "    r_theta = np.stack((np.cos(theta) * np.cos(phi),\n",
    "                        -np.sin(theta),\n",
    "                        -np.cos(theta) * np.sin(phi)), axis=-1)\n",
    "    r_phi = np.stack((-np.sin(phi),\n",
    "                      np.zeros_like(phi),\n",
    "                      -np.cos(phi)), axis=-1)\n",
    "\n",
    "    # Reshape perturbation vectors\n",
    "    p_t = np.concatenate([(d_theta[..., np.newaxis] * r)[..., np.newaxis],\n",
    "                          (k_u * d_batch[..., np.newaxis] * r_theta)[..., np.newaxis]], axis=-1)\n",
    "    \n",
    "    p_p = np.concatenate([(d_phi[..., np.newaxis] * r)[..., np.newaxis],\n",
    "                          (k_v * d_batch[..., np.newaxis] * r_phi)[..., np.newaxis]], axis=-1)\n",
    "\n",
    "    # Compute cross product of perturbation vectors to get normals\n",
    "    n_hat = np.cross(p_p, p_t)\n",
    "\n",
    "    # Normalize the normals\n",
    "    n_hat_norm = np.linalg.norm(n_hat, axis=-1, keepdims=True)\n",
    "    n_hat_norm = np.where(n_hat_norm > 0, n_hat_norm, 1)\n",
    "    n_hat = n_hat / n_hat_norm\n",
    "\n",
    "    return n_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba8f6dae-05e7-4377-968f-b28121a155f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2b53f51-7f51-4db2-90f3-5d341649614f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m reconstruct(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m, in \u001b[0;36mreconstruct\u001b[0;34m(d_batch)\u001b[0m\n\u001b[1;32m     13\u001b[0m batch_size, _, height, width \u001b[38;5;241m=\u001b[39m d_batch\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Compute gradients of the depth maps using Sobel filters\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m d_theta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([filters\u001b[38;5;241m.\u001b[39mscharr_h(d\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m d_batch])\n\u001b[1;32m     17\u001b[0m d_phi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([filters\u001b[38;5;241m.\u001b[39mscharr_v(d\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m d_batch])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Constants for converting pixel indices to spherical angles\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m batch_size, _, height, width \u001b[38;5;241m=\u001b[39m d_batch\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Compute gradients of the depth maps using Sobel filters\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m d_theta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([filters\u001b[38;5;241m.\u001b[39mscharr_h(d\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m d_batch])\n\u001b[1;32m     17\u001b[0m d_phi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([filters\u001b[38;5;241m.\u001b[39mscharr_v(d\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m d_batch])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Constants for converting pixel indices to spherical angles\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filters' is not defined"
     ]
    }
   ],
   "source": [
    "out = reconstruct(data['depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd935b03-500b-48f6-876c-6dd01345c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['depth'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b9faf8-2d9f-489d-b773-a9ff13718327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
