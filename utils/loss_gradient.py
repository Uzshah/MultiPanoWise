import torch
import torch.nn as nn
import torch.nn.functional as F
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class Gradient_Net(nn.Module):
  def __init__(self):
    super(Gradient_Net, self).__init__()
    kernel_x = [[-1., 0., 1.], [-2., 0., 2.], [-1., 0., 1.]]
    kernel_x = torch.FloatTensor(kernel_x).unsqueeze(0).unsqueeze(0).to(device)

    kernel_y = [[-1., -2., -1.], [0., 0., 0.], [1., 2., 1.]]
    kernel_y = torch.FloatTensor(kernel_y).unsqueeze(0).unsqueeze(0).to(device)
    self.weight_x = nn.Parameter(data=kernel_x, requires_grad=False)
    self.weight_y = nn.Parameter(data=kernel_y, requires_grad=False)

  def forward(self, x):
    grad_x = F.conv2d(x, self.weight_x, padding=1)
    grad_y = F.conv2d(x, self.weight_y, padding=1)
    gradient = torch.abs(grad_x) + torch.abs(grad_y)
    return torch.abs(grad_x), torch.abs(grad_y)


class Gradient_Net_3d(nn.Module):
  def __init__(self):
    super(Gradient_Net_3d, self).__init__()
    kernel_x = torch.Tensor([[-1., 0., 1.], [-2., 0., 2.], [-1., 0., 1.]]).view(1, 1, 3, 3).to(device)
    kernel_y = torch.Tensor([[-1., -2., -1.], [0., 0., 0.], [1., 2., 1.]]).view(1, 1, 3, 3).to(device)

    self.weight_x = nn.Parameter(data=kernel_x.expand(-1, 3, -1, -1), requires_grad=False)
    self.weight_y = nn.Parameter(data=kernel_y.expand(-1, 3, -1, -1), requires_grad=False)

  def forward(self, x):
    grad_x = F.conv2d(x, self.weight_x, padding=1)
    grad_y = F.conv2d(x, self.weight_y, padding=1)
    gradient = torch.abs(grad_x) + torch.abs(grad_y)
    return torch.abs(grad_x), torch.abs(grad_y)